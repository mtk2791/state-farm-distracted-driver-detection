{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification - MobileNet v2 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immport Libraries\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model (Keras built-in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mobile\n",
    "model = keras.applications.mobilenet_v2.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(filepath):\n",
    "   img = image.load_img(filepath, target_size=(224, 224))\n",
    "   img_array = image.img_to_array(img)\n",
    "   img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "   return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file='../input/images/German_Shepherd.jpg'\n",
    "Image(filename=img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file='imgs/train/c6/img_0.jpg'\n",
    "Image(filename=img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = 'imgs/train'\n",
    "test_directory = 'imgs/test/'\n",
    "\n",
    "random_test = '../input/driver/'\n",
    "num_classes=10\n",
    "classes = ['c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n",
    "\n",
    "prediction_dict= { \"0\": \"safe driving\",\n",
    "\"1\": \"texting - right\",\n",
    "\"2\": \"talking on the phone - right\",\n",
    "\"3\": \"texting - left\",\n",
    "\"4\": \"talking on the phone - left\",\n",
    "\"5\": \"operating the radio\",\n",
    "\"6\": \"drinking\",\n",
    "\"7\": \"reaching behind\",\n",
    "\"8\": \"hair and makeup\",\n",
    "\"9\": \"talking to passenger\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory('imgs/train/',\n",
    "                                                target_size=(224,224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model prediction\n",
    "preprocessed_image = prepare_image(img_file)\n",
    "predictions = model.predict(preprocessed_image)\n",
    "results = decode_predictions(predictions)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model (MobieNet V2)\n",
    "base_model=keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3),weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "# Add Extra Layers to Model\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check layers no. & name\n",
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set extra layers to trainable (layer #155~159)\n",
    "for layer in model.layers[:155]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[155:]:\n",
    "    layer.trainable=True\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model (target is loss <0.01)\n",
    "num_epochs = 5\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#model.save('Distract_Driver_detection_model.h5')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "model = keras.models.load_model('Distract_Driver_detection_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Convert to tensorflow lite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.0.0-alpha0\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import pathlib\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model('Distract_Driver_detection_model.h5')\n",
    "# tflite_model = converter.convert()\n",
    "# open(\"'Distract_Driver_detection_model.tflite\", \"wb\").write(tflite_model)\n",
    "converter=tf.lite.TFLiteConverter.from_keras.model(model)\n",
    "tflite_model_file=pathlib.Path('model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_file='../input/state-farm-distracted-driver-detection/imgs/test/img_100.jpg'\n",
    "Image(filename=img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new model\n",
    "preprocessed_image = prepare_image(img_file)\n",
    "predictions = model.predict(preprocessed_image)\n",
    "maxindex = int(np.argmax(predictions))\n",
    "print(predictions[0][maxindex],prediction_dict[maxindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file='imgs/test/img_10001.jpg'\n",
    "Image(filename=img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new model\n",
    "preprocessed_image = prepare_image(img_file)\n",
    "predictions = model.predict(preprocessed_image)\n",
    "maxindex = int(np.argmax(predictions))\n",
    "print(predictions[0][maxindex],prediction_dict[maxindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file='imgs/test/img_100016.jpg'\n",
    "Image(filename=img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new model\n",
    "preprocessed_image = prepare_image(img_file)\n",
    "predictions = model.predict(preprocessed_image)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "driver_imgs_list = pd.read_csv(\"driver_imgs_list.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/state-farm-distracted-driver-detection/sample_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
